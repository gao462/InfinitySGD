"""Run Infty-SGD Tasks

Usage:
    run.py [--seed <S>] [--device <id>] [--geo <p>] [--lr <lr>] [--alpha <alpha>]
           [--epoch <num>] [--loop <N>] [--from <id>] [--config <name>]
           (--simulate|--poisson) [--dataset <name>] [--trans <N>] [--useful]
           [--struct <name>]

Options:
    --seed <S>          Random seed.
    --device <id>       Device to work on.
                            No specification means CPU.
    --geo <p>           Geometry distribution parameter.
    --lr <lr>           Learning rate.
    --alpha <alpha>     Prior regularization strength.
    --epoch <num>       Number of training epochs.
    --loop <N>          Number of repeat times.
    --from <id>         Starting ID for loops.
    --config <name>     Name of differentiable Markov process configuration.
                            'rrinf', 'rr', 'inf', 'dc4', 'dc7' are supported.
    --simulate          Data is generated by real simulation.
    --poisson           Data is generated by Poisson.
    --dataset <name>    Name of dataset to learn.
                            'mm1k-small', 'mm1k-large', 'mmmmr', 'lbwb', 'emu' are supported.
    --trans <N>         Number of transitions to sample. [default: 0]
    --useful            Sample only useful transitions.
    --struct <name>     Name of prior structure to learn.

"""
import os
import math
import docopt
from schema import Schema, Use, And, Or
import task
import numpy as np
import scipy.stats as stats
import torch
import ddmp
import mcpro
import mcsim
import data

# parse arguments
args = docopt.docopt(__doc__, version='2.0')
requirements = {
    '--seed'    : Use(int, error='--seed argument must be int'),
    '--device'  : Or(None, Use(int), error='--device argument must be int'),
    '--geo'     : Use(float, error='--geo argument must be float'),
    '--lr'      : Use(float, error='--lr argument must be float'),
    '--alpha'   : Use(float, error='--alpha argument must be float'),
    '--epoch'   : Use(int, error='--epoch argument must be int'),
    '--loop'    : Use(int, error='--loop argument must be int'),
    '--from'    : Use(int, error='--from argument must be int'),
    '--config'  : Use(str, error='--config argument must be str'),
    '--simulate': Use(bool, error='--simulate argument must be bool'),
    '--poisson' : Use(bool, error='--poisson argument must be bool'),
    '--dataset' : Use(str, error='--dataset argument must be str'),
    '--trans'   : Use(int, error='--trans argument must be int'),
    '--useful'  : Use(bool, error='--useful argument must be bool'),
    '--struct'  : Use(str, error='--struct argument must be str'),
}
args = Schema(requirements).validate(args)
seed = args['--seed']
device = args['--device']
geo = args['--geo']
expog = int(math.log10(geo))
lr = args['--lr']
expol = int(math.log10(lr))
alpha = args['--alpha']
if alpha == 0:
    expoa = '-inf'
elif math.isinf(alpha) and alpha > 0:
    expoa = '+inf'
else:
    expoa = int(math.log10(alpha))
num_epochs = args['--epoch']
num_loops = args['--loop']
id_from = args['--from']
config = args['--config']
dataset = args['--dataset']
num_trans = args['--trans']
useful_trans = args['--useful']
struct = args['--struct']

# DC-BPTT should further parse z
if config[0:2] == 'dc':
    config1, config2 = 'dc', int(config[2:])
else:
    config1 = config

# reset data sampling process
if args['--simulate']:
    mcsim.PROCESS = 'simulate'
elif args['--poisson']:
    mcsim.PROCESS = 'poisson'
else:
    raise RuntimeError('there is no default sampling process.')

# task environment
if device is not None:
    device = "cuda:{}".format(device)
else:
    device = 'cpu'

# create task
t_tit = 'u' if useful_trans else 'n'
title = os.path.join('logs', "{}_{}{}_{}".format(dataset, t_tit, num_trans, struct))
if dataset in ('benchmark', 'mm1k', 'mmmmr', 'mm1k-small', 'mm1k-large'):
    task = task.Task(data_cls=data.MMmKData, root=title)
elif dataset in ('mmul', 'mmul-small', 'mmul-large'):
    task = task.Task(data_cls=data.MMMulKData, root=title)
elif dataset == 'emu':
    task = task.Task(data_cls=data.EmuData, root=title)
# // elif dataset == 'lbwb':
# //     task = task.Task(data_cls=data.WebBrowseData, root=title)
else:
    raise NotImplementedError
prefix = "{}_{}_g{}_a{}_l{}".format(title, config, expog, expoa, expol)

# define model
class PriorModel(torch.nn.Module):
    r"""Prior Struture Model"""
    def __init__(self, data_prior, tensor=torch.Tensor):
        r"""Initialize the class

        Args
        ----
        data_prior : object
            Data Prior holder.
        tensor : type
            Tesnor type used to hold parameters.

        """
        # super calling
        torch.nn.Module.__init__(self)

        # save necessary attributes
        self.k = data_prior.k
        self.c = data_prior.c

        # allocate parameter
        if expoa == '+inf':
            self.noise = None
        else:
            self.noise = torch.nn.Parameter(torch.zeros(self.k, self.k).type(tensor))
        self.pkargs = dict(noise=self.noise)
        if struct == 'mmmk':
            self.death_rate = torch.nn.Parameter(tensor([0]))
            self.pkargs['death_rate'] = self.death_rate
            self.prior = mcpro.MMmKPrior(
                k=data_prior.k, m=data_prior.m, c=data_prior.c, tensor=tensor,
                device=data_prior.device)
        elif struct == 'lbwb':
            self.buckt_rate = torch.nn.Parameter(tensor([0]))
            self.death_rate = torch.nn.Parameter(tensor([0]))
            self.pkargs['buckt_rate'] = self.buckt_rate
            self.pkargs['death_rate'] = self.death_rate
            self.prior = mcpro.WebBrowsePrior(
                u=data_prior.u, r=data_prior.r, b=data_prior.b, c=data_prior.c, tensor=tensor,
                device=data_prior.device)
        elif struct == 'up':
            self.lowtr_rate = torch.nn.Parameter(torch.zeros(self.k, self.k).type(tensor))
            for i in range(self.k):
                for j in range(i):
                    self.lowtr_rate.data[i, j] = 0
            self.pkargs['lowtr_rate'] = self.lowtr_rate 
            self.prior = mcpro.UpTriPrior(
                k=data_prior.k, c=data_prior.c, tensor=tensor,
                device=data_prior.device)
        elif struct == 'mmul':
            self.death_rate = torch.nn.Parameter(tensor([0 for _ in range(data_prior.d)]))
            self.pkargs['death_rate'] = self.death_rate
            self.prior = mcpro.MMMulKPrior(
                k=data_prior.k, d=data_prior.d, c=data_prior.c, tensor=tensor,
                device=data_prior.device)
        else:
            raise NotImplementedError

    def forward(self, birth_rate):
        r"""Forwarding

        Args
        ----
        birth_rate : torch.Tensor
            Birth rate.

        Returns
        -------
        P : torch.Tensor
            Transition probability matrix.
        pi : torch.Tensor
            Steady state distrbution vector.

        """
        # construct transition rate matrix
        X = self.prior.trans_rate_mx(birth_rate=birth_rate, **self.pkargs)

        # reach steady state distribution
        if config1 == 'dc':
            P, pi, _ = ddmp.stdy_dist(
                X, c=self.c, config='dc', dkargs=dict(rv=config2))
        elif config1 == 'inf':
            P, pi, _ = ddmp.stdy_dist(
                X, c=self.c, config='inf', dkargs=dict(rv=int(1 / geo)))
        else:
            P, pi, _ = ddmp.stdy_dist(
                X, c=self.c, config=config1, dkargs=dict(rvdist=(stats.geom, geo)))
        return P, pi

    @property
    def track_params(self):
        r"""Trackable parameters

        Returns
        -------
        params : tuple
            A tuple of trackable parameter values.

        """
        # return trackable parameters
        if struct == 'mmmk':
            return (self.death_rate.data.item(),)
        elif struct == 'lbwb':
            return (self.death_rate.data.item(), self.buckt_rate.data.item())
        elif struct == 'up':
            return (float('nan'),)
        elif struct == 'mmul':
            # return (float('nan'),)
            return tuple(self.death_rate.data.numpy().tolist())
        else:
            raise NotImplementedError

# configure data sharing attributes
if dataset == 'benchmark':
    share_kargs = dict(k=20, m=1, death_rate=25)
    train_kargs = dict(birth_vmin=11, birth_vmax=15, sample_times=10, num_trans=num_trans, useful_trans=useful_trans)
    valid_kargs = dict(birth_vmin=31, birth_vmax=60, sample_times=5 )
    test_kargs  = dict(birth_vmin=31, birth_vmax=60, sample_times=5 )
elif dataset == 'mm1k':
    share_kargs = dict(k=20, m=1, death_rate=25)
    train_kargs = dict(birth_vmin=11, birth_vmax=15, sample_times=10, num_trans=num_trans, useful_trans=useful_trans)
    valid_kargs = dict(birth_vmin=31, birth_vmax=60, sample_times=5 )
    test_kargs  = dict(birth_vmin=31, birth_vmax=60, sample_times=5 )
elif dataset == 'mmmmr':
    share_kargs = dict(k=20, m=5, death_rate=5)
    train_kargs = dict(birth_vmin=11, birth_vmax=15, sample_times=10, num_trans=num_trans, useful_trans=useful_trans)
    valid_kargs = dict(birth_vmin=31, birth_vmax=60, sample_times=5 )
    test_kargs  = dict(birth_vmin=31, birth_vmax=60, sample_times=5 )
elif dataset == 'mmul':
    share_kargs = dict(k=20, d=3, death_rate=[16, 8, 4])
    train_kargs = dict(birth_vmin=11, birth_vmax=15, sample_times=10, num_trans=num_trans, useful_trans=useful_trans)
    valid_kargs = dict(birth_vmin=31, birth_vmax=60, sample_times=5 )
    test_kargs  = dict(birth_vmin=31, birth_vmax=60, sample_times=5 )
elif dataset == 'emu':
    share_kargs = dict(qsz=20)
    train_kargs = dict(lamin=1   , lamax=1000)
    valid_kargs = dict(lamin=1   , lamax=1000)
    test_kargs  = dict(lamin=1001, lamax=9999)
# // elif dataset == 'mm1k-small':
# //     share_kargs = dict(k=20, m=1, death_rate=25)
# //     train_kargs = dict(birth_vmin=21, birth_vmax=30, sample_times=15, num_trans=num_trans, useful_trans=useful_trans)
# //     valid_kargs = dict(birth_vmin=21, birth_vmax=30, sample_times=15)
# //     test_kargs  = dict(birth_vmin=11, birth_vmax=40, sample_times=5 )
# // elif dataset == 'mm1k-large':
# //     share_kargs = dict(k=20, m=1, death_rate=25)
# //     train_kargs = dict(birth_vmin=11, birth_vmax=40, sample_times=5, num_trans=num_trans, useful_trans=useful_trans)
# //     valid_kargs = dict(birth_vmin=11, birth_vmax=40, sample_times=5)
# //     test_kargs  = dict(birth_vmin=11, birth_vmax=40, sample_times=5)
# // elif dataset == 'mmmmr':
# //     share_kargs = dict(k=20, m=10, death_rate=25)
# //     train_kargs = dict(birth_vmin=11, birth_vmax=40, sample_times=5, num_trans=num_trans, useful_trans=useful_trans)
# //     valid_kargs = dict(birth_vmin=11, birth_vmax=40, sample_times=5)
# //     test_kargs  = dict(birth_vmin=11, birth_vmax=40, sample_times=5)
# // elif dataset == 'lbwb':
# //     share_kargs = dict(u=5, r=3, b=2, bucket_rate=10, death_rate=25)
# //     train_kargs = dict(birth_vmin=11, birth_vmax=40, sample_times=5, num_trans=num_trans, useful_trans=useful_trans)
# //     valid_kargs = dict(birth_vmin=11, birth_vmax=40, sample_times=5)
# //     test_kargs  = dict(birth_vmin=11, birth_vmax=40, sample_times=5)
# // elif dataset == 'emu':
# //     share_kargs = dict(qsz=20)
# //     train_kargs = dict(lamin=1   , lamax=1000)
# //     valid_kargs = dict(lamin=1   , lamax=1000)
# //     test_kargs  = dict(lamin=1001, lamax=9999)
# // elif dataset == 'mmul-small':
# //     share_kargs = dict(k=20, d=3, death_rate=[15, 10, 5])
# //     train_kargs = dict(birth_vmin=26, birth_vmax=35, sample_times=15, num_trans=num_trans, useful_trans=useful_trans)
# //     valid_kargs = dict(birth_vmin=26, birth_vmax=35, sample_times=15)
# //     test_kargs  = dict(birth_vmin=16, birth_vmax=45, sample_times=5 )
# // elif dataset == 'mmul-large':
# //     share_kargs = dict(k=20, d=3, death_rate=[15, 10, 5])
# //     train_kargs = dict(birth_vmin=16, birth_vmax=45, sample_times=5, num_trans=num_trans, useful_trans=useful_trans)
# //     valid_kargs = dict(birth_vmin=16, birth_vmax=45, sample_times=5)
# //     test_kargs  = dict(birth_vmin=16, birth_vmax=45, sample_times=5)
else:
    raise NotImplementedError

# learn model
for i in range(num_loops):
    # print header
    print("\033[32;1m{}[ {} + \033[31;1m{}\033[32;1m / {} --> \033[33;1m{}\033[32;1m ]{}\033[0m".format(
        '=' * 10, seed, i, num_loops, id_from + i, '=' * 10))
    print("Data  : {} ({}{})".format(dataset, t_tit, num_trans))
    print("Prior : {}".format(struct))
    print("Config: {}".format(config))
    print("GeoP  : {}".format(geo))
    print("Alpha : {}".format(alpha))
    print("Lr    : {}".format(lr))
    print("Epoch : {}".format(num_epochs))
    print('-----')

    # explicitly generate data
    print('Generate')
    print('--------')
    train_kargs2 = dict(**share_kargs, **train_kargs, save="{}_train.pt".format(prefix))
    test_kargs2  = dict(**share_kargs, **test_kargs , save="{}_test.pt".format(prefix))
    if os.path.isfile(train_kargs2['save']):
        os.remove(train_kargs2['save'])
    else:
        pass
    if os.path.isfile(test_kargs2['save']):
        os.remove(test_kargs2['save'])
    else:
        pass
    task.generate(seed=seed + i, train_kargs=train_kargs2, valid_kargs=None, test_kargs=test_kargs2)

    # explicitly fit model for generated data
    print('Fit')
    print('---')
    task.fit(
        seed=seed + i, device=device, train_path=train_kargs2['save'], valid_path=test_kargs2['save'],
        model_cls=PriorModel, optim_cls=torch.optim.Adam, lr=lr, num_epochs=num_epochs, alpha=alpha,
        save="{}_{}.pt".format(prefix, id_from + i))

    # clean generated data
    os.remove(train_kargs2['save'])
    os.remove(test_kargs2['save'])